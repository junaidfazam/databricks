Delta Live Tables (DLT) is a framework in Databricks for building, managing, and orchestrating reliable ETL pipelines using declarative definitions. 
It simplifies how data engineers create data pipelines by automatically handling:
Data ingestion
Data transformations
Pipeline orchestration
Quality enforcement
Monitoring & recovery

Instead of writing complex job workflows, you declare what transformations should happen, and Databricks manages the how.

Why use LIVE in DLT
Because DLT is declarative, and LIVE tells the pipeline engine “this table/view is part of my pipeline, not some external object
1. Dependency Tracking (Lineage)
  CREATE OR REFRESH LIVE TABLE silver_orders
  AS SELECT * FROM LIVE.bronze_orders;
When you write FROM LIVE.bronze_orders, DLT knows that silver_orders depends on bronze_orders.
Without LIVE, DLT assumes it’s a normal external table in the catalog and won’t build dependency.

2. Automatic Orchestration
DLT figures out the order of execution by looking at LIVE references.
✅ With LIVE: Pipeline runs in the right order: Bronze → Silver → Gold.
❌ Without LIVE: DLT doesn’t know they’re connected, and execution may fail (“table not found”) or run in the wrong order.

3. Data Quality & Monitoring
Only LIVE tables/views show up in the DLT UI with validation results, data quality stats, and refresh logs.

4. Clear Separation of Scope
LIVE = pipeline-scoped object (defined inside this DLT pipeline).
No LIVE = external object (defined in Hive Metastore, Unity Catalog, or raw data files).
This makes it crystal clear whether you’re consuming:
Internal (pipeline-managed) data
External data sources

In SQL DLT: Always use LIVE.<table_name> when referencing other pipeline tables.
In Python DLT: Always use dlt.read("<table_name>")/dlt.read_stream().

Example code
CREATE OR REFRESH LIVE TABLE gold_orders
AS SELECT customer_id, SUM(amount) as total
FROM LIVE.silver_orders
GROUP BY customer_id;

import dlt
@dlt.table
def bronze_orders():
    return spark.read.json("/mnt/data/orders.json")
@dlt.table
def silver_orders():
    return dlt.read("bronze_orders").filter("amount > 0")

Table Types in Databricks & DLT

1. Managed Table
Databricks manages both metadata + storage.
Default when you create a table in DLT (inside the pipeline’s storage).
Dropping the table removes the data.

CREATE OR REFRESH LIVE TABLE customers_bronze
AS SELECT * FROM cloud_files("/mnt/data/customers", "csv");

import dlt
@dlt.table
def customers_bronze():
    return spark.read.csv("/mnt/data/customers.csv", header=True)


2. External Table
Data lives in your chosen location (e.g., /mnt/external/...).
Dropping the table removes metadata only (files remain).
Use when raw data is shared across multiple systems.
Useful when you don’t want Databricks to own lifecycle of data.

CREATE OR REFRESH LIVE TABLE external_sales
LOCATION "/mnt/external/sales"
AS SELECT * FROM cloud_files("/mnt/raw/sales", "csv");



Views in Databricks & DLT

1. Live View
Logical, not persisted.
Recomputed each time you query it.
Used for intermediate transformations

CREATE OR REFRESH LIVE VIEW active_customers
AS SELECT * FROM LIVE.customers_bronze WHERE email IS NOT NULL;


2. Materialized View (⚠ not part of DLT, but Databricks SQL)
Stores results like a table.
Incrementally refreshed.
Best for BI dashboards when query performance matters.
Materialized views usually sit after Gold tables in the analytics/BI layer.

CREATE MATERIALIZED VIEW gold_customer_summary
AS SELECT customer_id, COUNT(*) AS order_count
FROM sales
GROUP BY customer_id;


Bronze → Silver → Gold with DLT
Raw JSON (orders.json) file
{"order_id": 1, "customer_id": "C001", "amount": 100, "status": "active"}
{"order_id": 2, "customer_id": "C002", "amount": 0, "status": "cancelled"}
{"order_id": 3, "customer_id": "C001", "amount": 250, "status": "active"}

Bronze (Raw Ingest)

CREATE OR REFRESH STREAMING LIVE TABLE bronze_orders
AS SELECT * FROM cloud_files("/mnt/data/orders", "json");

Silver (Cleaned / Validated)

CREATE OR REFRESH LIVE TABLE silver_orders
AS SELECT order_id, customer_id, amount
FROM LIVE.bronze_orders
WHERE amount > 0;

Gold (Business-Ready)

CREATE OR REFRESH LIVE TABLE gold_customer_sales
AS SELECT customer_id, SUM(amount) AS total_spent
FROM LIVE.silver_orders
GROUP BY customer_id;

Live View (Intermediate Transformation)

CREATE OR REFRESH LIVE VIEW active_orders
AS SELECT * FROM LIVE.silver_orders WHERE status = 'active';

Materialized View (BI Layer)

CREATE MATERIALIZED VIEW customer_sales_summary
AS SELECT * FROM gold_customer_sales;

Quick Comparison

| Feature                | Managed Table (DLT default) | External Table            | Live View (DLT)      | Materialized View           |
| ---------------------- | --------------------------- | ------------------------- | -------------------- | --------------------------- |
| **Stored on disk**     | ✅ Yes                       | ✅ Yes                     | ❌ No                 | ✅ Yes                       |
| **Storage managed by** | Databricks                  | You (user-specified path) | N/A                  | Databricks SQL engine       |
| **Refresh**            | Auto by pipeline            | Auto by pipeline          | On query             | Incremental                 |
| **Best for**           | Bronze/Silver/Gold layers   | Shared raw/curated data   | Temp transformations | Repeated aggregations in BI |


